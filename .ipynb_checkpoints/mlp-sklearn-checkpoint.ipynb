{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de un Perceptrón Multicapa de Tres Capas con `sklearn.neural_network`\n",
    "\n",
    "En este notebook, aprenderás a crear un perceptrón multicapa (MLP, por sus siglas en inglés) de tres capas utilizando la librería `sklearn.neural_network`. Cubriremos todo el pipeline de la tarea de clasificación, desde la generación del dataset hasta la evaluación del modelo.\n",
    "\n",
    "## Objetivos:\n",
    "1. Generar un dataset sintético con al menos cinco variables independientes.\n",
    "2. Dividir el dataset en conjuntos de entrenamiento y prueba.\n",
    "3. Normalizar los datos.\n",
    "4. Crear y entrenar un perceptrón multicapa de tres capas.\n",
    "5. Evaluar el modelo utilizando la matriz de confusión y la curva de error.\n",
    "6. Explicar cada función y sus argumentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 1: Importación de Librerías\n",
    "\n",
    "Primero, importamos las librerías necesarias para el proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 2: Generación del Dataset\n",
    "\n",
    "Utilizamos la función `make_classification` de `sklearn` para generar un dataset sintético con cinco variables independientes y dos clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar dataset sintético\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,  # Número de muestras\n",
    "    n_features=5,    # Número de características (variables independientes)\n",
    "    n_classes=2,     # Número de clases\n",
    "    n_informative=5, # Características informativas\n",
    "    n_redundant=0,   # Características redundantes\n",
    "    random_state=42  # Semilla para reproducibilidad\n",
    ")\n",
    "\n",
    "# Convertir a DataFrame para visualización\n",
    "df = pd.DataFrame(X, columns=[f'Feature_{i+1}' for i in range(5)])\n",
    "df['Target'] = y\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "print(\"Primeras filas del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 3: División del Dataset\n",
    "\n",
    "Dividimos el dataset en conjuntos de entrenamiento (70%) y prueba (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Tamaño del conjunto de prueba: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 4: Normalización de los Datos\n",
    "\n",
    "Normalizamos los datos para que tengan media 0 y desviación estándar 1. Esto es importante para el entrenamiento de redes neuronales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Datos normalizados:\")\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 5: Creación del Perceptrón Multicapa\n",
    "\n",
    "Creamos un perceptrón multicapa de tres capas utilizando `MLPClassifier`. Las capas son:\n",
    "- Capa oculta 1: 10 neuronas\n",
    "- Capa oculta 2: 5 neuronas\n",
    "- Capa de salida: 1 neurona (para clasificación binaria)\n",
    "\n",
    "### Argumentos principales de `MLPClassifier`:\n",
    "- `hidden_layer_sizes=(10, 5)`: Define dos capas ocultas con 10 y 5 neuronas, respectivamente.\n",
    "- `activation='relu'`: Función de activación ReLU.\n",
    "- `solver='adam'`: Optimizador Adam.\n",
    "- `max_iter=1000`: Número máximo de iteraciones.\n",
    "- `learning_rate_init=0.01`: Tasa de aprendizaje inicial.\n",
    "- `random_state=42`: Semilla para reproducibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(10, 5),  # Dos capas ocultas con 10 y 5 neuronas\n",
    "    activation='relu',           # Función de activación ReLU\n",
    "    solver='adam',               # Optimizador Adam\n",
    "    max_iter=1000,               # Número máximo de iteraciones\n",
    "    learning_rate_init=0.01,     # Tasa de aprendizaje inicial\n",
    "    random_state=42              # Semilla para reproducibilidad\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Entrenamiento completado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 6: Predicciones y Evaluación\n",
    "\n",
    "Realizamos predicciones en el conjunto de prueba y evaluamos el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 7: Matriz de Confusión\n",
    "\n",
    "La **matriz de confusión** es una herramienta para evaluar el rendimiento de un modelo de clasificación. Muestra la cantidad de predicciones correctas e incorrectas para cada clase.\n",
    "\n",
    "### Estructura:\n",
    "|                     | Predicción: Clase 0 | Predicción: Clase 1 |\n",
    "|---------------------|---------------------|---------------------|\n",
    "| **Real: Clase 0**   | Verdaderos Negativos (TN) | Falsos Positivos (FP) |\n",
    "| **Real: Clase 1**   | Falsos Negativos (FN) | Verdaderos Positivos (TP) |\n",
    "\n",
    "### Métricas derivadas:\n",
    "- **Precisión = TP / (TP + FP)**\n",
    "- **Recall (Sensibilidad) = TP / (TP + FN)**\n",
    "- **Exactitud = (TP + TN) / (TP + TN + FP + FN)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Visualización\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Clase 0\", \"Clase 1\"], yticklabels=[\"Clase 0\", \"Clase 1\"])\n",
    "plt.xlabel(\"Predicción\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.title(\"Matriz de Confusión\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 8: Curva de Error\n",
    "\n",
    "La **curva de error** muestra cómo disminuye el error durante el entrenamiento. Esto nos ayuda a verificar si el modelo está convergiendo correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curva de error\n",
    "plt.plot(mlp.loss_curve_)\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Curva de Error durante el Entrenamiento\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paso 9: Reporte de Clasificación\n",
    "\n",
    "El **reporte de clasificación** proporciona métricas detalladas como precisión, recall y F1-score para cada clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

