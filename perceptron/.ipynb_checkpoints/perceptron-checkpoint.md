# Entrenamiento de un Perceptr√≥n para la Compuerta AND

Un **perceptr√≥n** es un modelo de neurona artificial que se usa para clasificar datos linealmente separables. En este caso, entrenaremos un perceptr√≥n para aprender la compuerta l√≥gica **AND**.

## 1. Definici√≥n de la Compuerta AND
La compuerta l√≥gica AND tiene la siguiente tabla de verdad:

| Entrada x1 | Entrada x2 | Salida AND |
|------------|------------|-------------|
| 0          | 0          | 0           |
| 0          | 1          | 0           |
| 1          | 0          | 0           |
| 1          | 1          | 1           |

## 2. Modelo del Perceptr√≥n

$$\hat{y}=g\left(\sum_{i=1}  w_i x_i\right)$$

$$\hat{y}=g\left(w_0+\sum_{i=1}^m x_i w_i\right)$$

$$
 y = f(w_1 x_1 + w_2 x_2 + b)
$$

donde:
- $( x_1, x_2 )$ son las entradas.
- $( w_1, w_2 )$ son los pesos.
- \( b \) es el sesgo.
- \( f(z) √≥ g(z) \) es la funci√≥n de activaci√≥n (usamos la funci√≥n escal√≥n de Heaviside):

$$
g(z) = f(z) = 
\begin{cases}
1, & \text{si } z \geq 0 \\
0, & \text{si } z < 0
\end{cases}
$$

## 3. Algoritmo de Entrenamiento
Se usa la **regla de actualizaci√≥n de pesos**:

$$w_i^{(t+1)} = w_i^{(t)} + \eta (y - \hat{y}) x_i$$

$$
b^{(t+1)} = b^{(t)} + \eta (y - \hat{y})
$$

donde:
- $( \eta )$ es la tasa de aprendizaje (usaremos 0.1).
- $( y )$ es la salida esperada.
- $( \hat{y} )$ es la salida predicha por el perceptr√≥n.

### Inicializaci√≥n de Par√°metros

- La inicializaci√≥n es arbitraria

Supongamos:
- $w_1 = 0$
- $w_2 = 0$, 
- $b = 0$
- $\eta = 0.1$

### Iteraci√≥n Paso a Paso
#### **√âpoca 1**
Para cada muestra, calculamos la salida $( \hat{y} )$ y actualizamos los pesos si es necesario.

1. **Entrada (0,0) ‚Üí Salida esperada: 0**
   - $( z = (0 \times 0) + (0 \times 0) + 0 = 0 )$
   - $( \hat{y} = f(0) = 1 )$ ‚Üí Incorrecto

   - Actualizaci√≥n:
     - $( w_1 = 0 + 0.1 (0 - 1) (0) = 0 )$
     - $( w_2 = 0 + 0.1 (0 - 1) (0) = 0 )$
     - $( b = 0 + 0.1 (0 - 1) = -0.1 )$

2. **Entrada (0,1) ‚Üí Salida esperada: 0**
   - $( z = (0 \times 0) + (0 \times 1) - 0.1 = -0.1 )$
   - $( \hat{y} = f(-0.1) = 0 )$ ‚Üí Correcto
   - No se actualizan pesos.

3. **Entrada (1,0) ‚Üí Salida esperada: 0**
   - $( z = (0 \times 1) + (0 \times 0) - 0.1 = -0.1 )$
   - $( \hat{y} = f(-0.1) = 0 )$ ‚Üí Correcto
   - No se actualizan pesos.

4. **Entrada (1,1) ‚Üí Salida esperada: 1**
   - $( z = (0 \times 1) + (0 \times 1) - 0.1 = -0.1 )$
   - $( \hat{y} = f(-0.1) = 0 )$ ‚Üí Incorrecto

   - Actualizaci√≥n:
     - $( w_1 = 0 + 0.1 (1 - 0) (1) = 0.1 )$
     - $( w_2 = 0 + 0.1 (1 - 0) (1) = 0.1 )$
     - $( b = -0.1 + 0.1 (1 - 0) = 0 )$

#### **√âpoca 2**

Revisamos si el modelo ya clasifica correctamente.
- (0,0) ‚Üí \( z = 0 \), \( $\hat{y}$ = 0 \) ‚Üí Correcto.
- (0,1) ‚Üí \( z = 0.1 \), \( $\hat{y}$ = 0 \) ‚Üí Correcto.
- (1,0) ‚Üí \( z = 0.1 \), \( $\hat{y}$ = 0 \) ‚Üí Correcto.
- (1,1) ‚Üí \( z = 0.2 \), \( $\hat{y}$ = 1 \) ‚Üí Correcto.

Como todas las predicciones son correctas, el modelo ha aprendido la compuerta AND con:

$$w_1 = 0.1, \quad w_2 = 0.1, \quad b = 0$$

### 4. Expresi√≥n Final del Perceptr√≥n AND
El perceptr√≥n aprendido implementa la siguiente ecuaci√≥n:

$$y = f(0.1x_1 + 0.1x_2)$$


Este modelo ahora clasifica correctamente todas las entradas de la compuerta AND. üéØ


